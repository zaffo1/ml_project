{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_euclidean_error(vectors1, vectors2):\n",
    "    \"\"\"\n",
    "    Compute the mean Euclidean error between two sets of 3D vectors.\n",
    "\n",
    "    Parameters:\n",
    "    - vectors1: NumPy array of shape (N, 3) representing the first set of 3D vectors\n",
    "    - vectors2: NumPy array of shape (N, 3) representing the second set of 3D vectors\n",
    "\n",
    "    Returns:\n",
    "    - mean_error: Mean Euclidean error between the two sets of vectors\n",
    "    \"\"\"\n",
    "    # Check if the input arrays have the correct shape\n",
    "    if vectors1.shape != vectors2.shape or vectors1.shape[1] != 3:\n",
    "        raise ValueError(\"Input arrays must be of shape (N, 3)\")\n",
    "\n",
    "    # Compute Euclidean distance\n",
    "    euclidean_distance = np.linalg.norm(vectors1 - vectors2, axis=1)\n",
    "\n",
    "    # Calculate the mean Euclidean error\n",
    "    mean_error = np.mean(euclidean_distance)\n",
    "\n",
    "    return mean_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# load the dataset, split into input (X) and output (y) variables\n",
    "dataset = np.loadtxt('ML-CUP23-TR.csv', delimiter=',')\n",
    "X = dataset[:,1:11]\n",
    "y = dataset[:,11:14]\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets (80%/20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiSVM:\n",
    "    def __init__(self, kernel='rbf', C0=1.0, C1=1.0, C2=1.0, epsilon0=0.1, epsilon1=0.1, epsilon2=0.1):\n",
    "        # Create three support vector regressors with the specified kernel, regularization parameter, and epsilon\n",
    "        self.svr0 = SVR(kernel=kernel, C=C0, epsilon=epsilon0)\n",
    "        self.svr1 = SVR(kernel=kernel, C=C1, epsilon=epsilon1)\n",
    "        self.svr2 = SVR(kernel=kernel, C=C2, epsilon=epsilon2)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Fit each SVR on its respective data\n",
    "        self.svr0.fit(X, y[:,0])\n",
    "        self.svr1.fit(X, y[:,1])\n",
    "        self.svr2.fit(X, y[:,2])\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions using each SVR\n",
    "        pred = np.column_stack((self.svr0.predict(X),self.svr1.predict(X),self.svr2.predict(X)))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search_kfold(kernels, C0s, C1s, C2s, epsilon0s, epsilon1s, epsilon2s, k_folds, x, y):\n",
    "    \"\"\"\n",
    "    Perform grid search with k-fold cross-validation for hyperparameters.\n",
    "\n",
    "    Parameters:\n",
    "    - neuron_numbers (list): List of neuron numbers to search.\n",
    "    - learning_rates (list): List of learning rates to search.\n",
    "    - momentums (list): List of momentum values to search.\n",
    "    - batch_sizes (list): List of batch sizes to search.\n",
    "    - reg_coeffs (list): List of regularization coefficients to search.\n",
    "    - activations (list): List of activation functions to search.\n",
    "    - layerss (list): List of numbers of hidden layers to search.\n",
    "    - k_folds (int): Number of folds for cross-validation.\n",
    "    - x (numpy.ndarray): Input data.\n",
    "    - y (numpy.ndarray): Target data.\n",
    "    - plot_curves (bool, optional): Whether to plot training curves (default: False).\n",
    "    - num_epochs (int, optional): Number of training epochs (default: 1000).\n",
    "\n",
    "    Returns:\n",
    "    - list: List of best hyperparameters.\n",
    "\n",
    "    The function performs grid search with k-fold cross-validation for Monk classifier hyperparameters and returns the best hyperparameters.\n",
    "    \"\"\"\n",
    "\n",
    "    best_mee = float('inf')\n",
    "    best_hyperparams = []\n",
    "    counter = 0\n",
    "    num_combinations = sum(1 for _ in product(kernels, C0s, C1s, C2s, epsilon0s, epsilon1s, epsilon2s))\n",
    "    print('total number of grid search combinations explored:',num_combinations)\n",
    "    for kernel, C0, C1, C2, epsilon0, epsilon1, epsilon2 in product(kernels, C0s, C1s, C2s, epsilon0s, epsilon1s, epsilon2s):\n",
    "        counter += 1\n",
    "        print(f'{counter}/{num_combinations} Hyperparams:',kernel, C0, C1, C2, epsilon0, epsilon1, epsilon2)\n",
    "\n",
    "        kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "        val_mees = []\n",
    "\n",
    "        # Perform K-fold cross-validation\n",
    "        for fold, (train_indices, val_indices) in enumerate(kf.split(x,y)):\n",
    "            #print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "\n",
    "            # Split the data into training and validation (or test) sets\n",
    "            X_train, X_val = x[train_indices], x[val_indices]\n",
    "            y_train, y_val = y[train_indices], y[val_indices]\n",
    "\n",
    "            model = MultiSVM(kernel, C0, C1, C2, epsilon0, epsilon1, epsilon2)\n",
    "            model.fit(X_train,y_train)\n",
    "            val_mees.append(mean_euclidean_error(model.predict(X_val),y_val))\n",
    "\n",
    "        print(f'Final Results: kernel={kernel}; C={C0,C1,C2}; epsilon={epsilon0,epsilon1,epsilon2} --> '\n",
    "            f'val_mee = {np.mean(val_mees):.4} +- {np.std(val_mees):.4}')\n",
    "\n",
    "        if np.mean(val_mees) < best_mee:\n",
    "            best_mee = np.mean(val_mees)\n",
    "            best_hyperparams = [kernel, C0, C1, C2, epsilon0, epsilon1, epsilon2]\n",
    "\n",
    "    print('Best Hp:',best_hyperparams)\n",
    "    return best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = MultiSVM(kernel='rbf', C0=100, C1=100, C2=100, epsilon0=0.1, epsilon1=0.1, epsilon2=0.1)\\nmodel.fit(X_train,y_train)\\ny_pred = model.predict(X_test)\\n\\nmean_euclidean_error(y_pred,y_test)\\n\\n\""
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model = MultiSVM(kernel='rbf', C0=100, C1=100, C2=100, epsilon0=0.1, epsilon1=0.1, epsilon2=0.1)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mean_euclidean_error(y_pred,y_test)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of grid search combinations explored: 729\n",
      "1/729 Hyperparams: rbf 100 100 100 0.1 0.1 0.1\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.1, 0.1, 0.1) --> val_mee = 0.8765 +- 0.07218\n",
      "2/729 Hyperparams: rbf 100 100 100 0.1 0.1 0.2\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.1, 0.1, 0.2) --> val_mee = 0.8802 +- 0.0692\n",
      "3/729 Hyperparams: rbf 100 100 100 0.1 0.1 0.3\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.1, 0.1, 0.3) --> val_mee = 0.8929 +- 0.06706\n",
      "4/729 Hyperparams: rbf 100 100 100 0.1 0.2 0.1\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.1, 0.2, 0.1) --> val_mee = 0.873 +- 0.06825\n",
      "5/729 Hyperparams: rbf 100 100 100 0.1 0.2 0.2\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.1, 0.2, 0.2) --> val_mee = 0.8766 +- 0.06548\n",
      "6/729 Hyperparams: rbf 100 100 100 0.1 0.2 0.3\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.1, 0.2, 0.3) --> val_mee = 0.8893 +- 0.06333\n",
      "7/729 Hyperparams: rbf 100 100 100 0.1 0.3 0.1\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.1, 0.3, 0.1) --> val_mee = 0.8819 +- 0.06403\n",
      "8/729 Hyperparams: rbf 100 100 100 0.1 0.3 0.2\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.1, 0.3, 0.2) --> val_mee = 0.8856 +- 0.06151\n",
      "9/729 Hyperparams: rbf 100 100 100 0.1 0.3 0.3\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.1, 0.3, 0.3) --> val_mee = 0.898 +- 0.05929\n",
      "10/729 Hyperparams: rbf 100 100 100 0.2 0.1 0.1\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.2, 0.1, 0.1) --> val_mee = 0.8925 +- 0.07371\n",
      "11/729 Hyperparams: rbf 100 100 100 0.2 0.1 0.2\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.2, 0.1, 0.2) --> val_mee = 0.896 +- 0.07105\n",
      "12/729 Hyperparams: rbf 100 100 100 0.2 0.1 0.3\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.2, 0.1, 0.3) --> val_mee = 0.9085 +- 0.06886\n",
      "13/729 Hyperparams: rbf 100 100 100 0.2 0.2 0.1\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.2, 0.2, 0.1) --> val_mee = 0.889 +- 0.06967\n",
      "14/729 Hyperparams: rbf 100 100 100 0.2 0.2 0.2\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.2, 0.2, 0.2) --> val_mee = 0.8924 +- 0.0673\n",
      "15/729 Hyperparams: rbf 100 100 100 0.2 0.2 0.3\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.2, 0.2, 0.3) --> val_mee = 0.9047 +- 0.06512\n",
      "16/729 Hyperparams: rbf 100 100 100 0.2 0.3 0.1\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.2, 0.3, 0.1) --> val_mee = 0.8977 +- 0.06535\n",
      "17/729 Hyperparams: rbf 100 100 100 0.2 0.3 0.2\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.2, 0.3, 0.2) --> val_mee = 0.9012 +- 0.06313\n",
      "18/729 Hyperparams: rbf 100 100 100 0.2 0.3 0.3\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.2, 0.3, 0.3) --> val_mee = 0.9133 +- 0.06091\n",
      "19/729 Hyperparams: rbf 100 100 100 0.3 0.1 0.1\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.3, 0.1, 0.1) --> val_mee = 0.9045 +- 0.07748\n",
      "20/729 Hyperparams: rbf 100 100 100 0.3 0.1 0.2\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.3, 0.1, 0.2) --> val_mee = 0.9077 +- 0.07507\n",
      "21/729 Hyperparams: rbf 100 100 100 0.3 0.1 0.3\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.3, 0.1, 0.3) --> val_mee = 0.9199 +- 0.07293\n",
      "22/729 Hyperparams: rbf 100 100 100 0.3 0.2 0.1\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.3, 0.2, 0.1) --> val_mee = 0.901 +- 0.07359\n",
      "23/729 Hyperparams: rbf 100 100 100 0.3 0.2 0.2\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.3, 0.2, 0.2) --> val_mee = 0.9041 +- 0.07152\n",
      "24/729 Hyperparams: rbf 100 100 100 0.3 0.2 0.3\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.3, 0.2, 0.3) --> val_mee = 0.9161 +- 0.06938\n",
      "25/729 Hyperparams: rbf 100 100 100 0.3 0.3 0.1\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.3, 0.3, 0.1) --> val_mee = 0.9095 +- 0.06927\n",
      "26/729 Hyperparams: rbf 100 100 100 0.3 0.3 0.2\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.3, 0.3, 0.2) --> val_mee = 0.9127 +- 0.06731\n",
      "27/729 Hyperparams: rbf 100 100 100 0.3 0.3 0.3\n",
      "Final Results: kernel=rbf; C=(100, 100, 100); epsilon=(0.3, 0.3, 0.3) --> val_mee = 0.9245 +- 0.06509\n",
      "28/729 Hyperparams: rbf 100 100 200 0.1 0.1 0.1\n",
      "Final Results: kernel=rbf; C=(100, 100, 200); epsilon=(0.1, 0.1, 0.1) --> val_mee = 0.8559 +- 0.0708\n",
      "29/729 Hyperparams: rbf 100 100 200 0.1 0.1 0.2\n",
      "Final Results: kernel=rbf; C=(100, 100, 200); epsilon=(0.1, 0.1, 0.2) --> val_mee = 0.864 +- 0.06854\n",
      "30/729 Hyperparams: rbf 100 100 200 0.1 0.1 0.3\n",
      "Final Results: kernel=rbf; C=(100, 100, 200); epsilon=(0.1, 0.1, 0.3) --> val_mee = 0.8762 +- 0.06635\n",
      "31/729 Hyperparams: rbf 100 100 200 0.1 0.2 0.1\n",
      "Final Results: kernel=rbf; C=(100, 100, 200); epsilon=(0.1, 0.2, 0.1) --> val_mee = 0.8523 +- 0.0667\n",
      "32/729 Hyperparams: rbf 100 100 200 0.1 0.2 0.2\n",
      "Final Results: kernel=rbf; C=(100, 100, 200); epsilon=(0.1, 0.2, 0.2) --> val_mee = 0.8603 +- 0.06453\n",
      "33/729 Hyperparams: rbf 100 100 200 0.1 0.2 0.3\n",
      "Final Results: kernel=rbf; C=(100, 100, 200); epsilon=(0.1, 0.2, 0.3) --> val_mee = 0.8724 +- 0.06249\n",
      "34/729 Hyperparams: rbf 100 100 200 0.1 0.3 0.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[162], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m epsilon1s \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.1\u001b[39m,\u001b[38;5;241m0.2\u001b[39m,\u001b[38;5;241m0.3\u001b[39m] \n\u001b[1;32m      7\u001b[0m epsilon2s \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.1\u001b[39m,\u001b[38;5;241m0.2\u001b[39m,\u001b[38;5;241m0.3\u001b[39m]  \n\u001b[0;32m----> 9\u001b[0m best_hyperparams \u001b[38;5;241m=\u001b[39m \u001b[43mperform_grid_search_kfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mC0s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mC1s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mC2s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mepsilon0s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mepsilon1s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mepsilon2s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                          \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[160], line 46\u001b[0m, in \u001b[0;36mperform_grid_search_kfold\u001b[0;34m(kernels, C0s, C1s, C2s, epsilon0s, epsilon1s, epsilon2s, k_folds, x, y)\u001b[0m\n\u001b[1;32m     43\u001b[0m     y_train, y_val \u001b[38;5;241m=\u001b[39m y[train_indices], y[val_indices]\n\u001b[1;32m     45\u001b[0m     model \u001b[38;5;241m=\u001b[39m MultiSVM(kernel, C0, C1, C2, epsilon0, epsilon1, epsilon2)\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     val_mees\u001b[38;5;241m.\u001b[39mappend(mean_euclidean_error(model\u001b[38;5;241m.\u001b[39mpredict(X_val),y_val))\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinal Results: kernel=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; C=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mC0,C1,C2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; epsilon=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepsilon0,epsilon1,epsilon2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --> \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mee = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(val_mees)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m +- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(val_mees)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[159], line 11\u001b[0m, in \u001b[0;36mMultiSVM.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Fit each SVR on its respective data\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvr0\u001b[38;5;241m.\u001b[39mfit(X, y[:,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvr1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvr2\u001b[38;5;241m.\u001b[39mfit(X, y[:,\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/Magistrale/ML/env_ml/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Magistrale/ML/env_ml/lib/python3.10/site-packages/sklearn/svm/_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m--> 250\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m~/Desktop/Magistrale/ML/env_ml/lib/python3.10/site-packages/sklearn/svm/_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    315\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[1;32m    319\u001b[0m (\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[0;32m--> 329\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_class_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "File \u001b[0;32msklearn/svm/_libsvm.pyx:265\u001b[0m, in \u001b[0;36msklearn.svm._libsvm.fit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kernels = ['rbf']\n",
    "C0s = [100,200,300]\n",
    "C1s = [100,200,300]\n",
    "C2s = [100,200,300]\n",
    "epsilon0s = [0.1,0.2,0.3]\n",
    "epsilon1s = [0.1,0.2,0.3]\n",
    "epsilon2s = [0.1,0.2,0.3]\n",
    "\n",
    "best_hyperparams = perform_grid_search_kfold(kernels,\n",
    "                          C0s,\n",
    "                          C1s,\n",
    "                          C2s,\n",
    "                          epsilon0s,\n",
    "                          epsilon1s,\n",
    "                          epsilon2s,\n",
    "                          k_folds=5,\n",
    "                          x=X_train,\n",
    "                          y=y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
