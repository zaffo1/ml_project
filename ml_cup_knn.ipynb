{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML CUP - k-NN\n",
    "In this notebook we will study the application of k-NN networks to the ML CUP.\n",
    "In particular we focus on the effect of the **hyperparameter k**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 16\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)    # fontsize of the figure suptitle\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_euclidean_error(vectors1, vectors2):\n",
    "    \"\"\"\n",
    "    Compute the mean Euclidean error between two sets of 3D vectors.\n",
    "\n",
    "    Parameters:\n",
    "    - vectors1: NumPy array of shape (N, 3) representing the first set of 3D vectors\n",
    "    - vectors2: NumPy array of shape (N, 3) representing the second set of 3D vectors\n",
    "\n",
    "    Returns:\n",
    "    - mean_error: Mean Euclidean error between the two sets of vectors\n",
    "    \"\"\"\n",
    "    # Check if the input arrays have the correct shape\n",
    "    if vectors1.shape != vectors2.shape or vectors1.shape[1] != 3:\n",
    "        raise ValueError(\"Input arrays must be of shape (N, 3)\")\n",
    "\n",
    "    # Compute Euclidean distance\n",
    "    euclidean_distance = np.linalg.norm(vectors1 - vectors2, axis=1)\n",
    "\n",
    "    # Calculate the mean Euclidean error\n",
    "    mean_error = np.mean(euclidean_distance)\n",
    "\n",
    "    return mean_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_std(x,mee,std, label, color):\n",
    "    \"\"\"\n",
    "    Plot mean Euclidean error (MEE) and standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    - x (array-like): An array-like object containing the values of the hyperparameter.\n",
    "    - mee (array-like): An array-like object containing the mean Euclidean error for each hyperparameter value.\n",
    "    - std (array-like): An array-like object containing the standard deviation of the Euclidean error for each hyperparameter value.\n",
    "    - label (str): Label for the x-axis, typically representing the name of the hyperparameter.\n",
    "    - color (str): Color code (name or hexadecimal) for the plot line and shaded area.\n",
    "\n",
    "    The function plots a line for the MEE and shades the area between MEE Â± standard deviation\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.plot(x,mee, label='MEE $\\pm$ std. (results of k-fold cross validation)', color = color, linewidth=1)\n",
    "    plt.fill_between(x,mee-std, mee+std, color=color, alpha=0.3)\n",
    "\n",
    "    plt.xlabel(f'{label} values')\n",
    "    plt.ylabel('MEE')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load the dataset, split into input (X) and output (y) variables\n",
    "dataset = np.loadtxt('ML-CUP23-TR.csv', delimiter=',')\n",
    "X = dataset[:,1:11]\n",
    "y = dataset[:,11:14]\n",
    "\n",
    "# Split the data into training and test sets (80%/20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a custom scorer to use MEE\n",
    "from sklearn.metrics import make_scorer\n",
    "mean_euclidean_scorer = make_scorer(mean_euclidean_error, greater_is_better=False)\n",
    "\n",
    "def perform_grid_search_kfold(ks,weightss,ps, k_folds, X, y):\n",
    "    \"\"\"\n",
    "    Perform grid search to find the best hyperparameters for K-Nearest Neighbors Regressor\n",
    "    using K-Fold cross-validation based on Mean Euclidean Error.\n",
    "\n",
    "    Iterate over all combinations of specified hyperparameters,\n",
    "    evaluates performance using K-Fold cross-validation, and identify the best combination based\n",
    "    on the lowest MEE.\n",
    "\n",
    "    Parameters:\n",
    "    - ks (list of int): A list of values to try for the 'n_neighbors' hyperparameter in KNN.\n",
    "    - weightss (list of str): A list of weight options (e.g., 'uniform', 'distance') to evaluate in KNN.\n",
    "    - ps (list of int): A list of values to try for the 'p' hyperparameter in KNN, determining the power parameter for the Minkowski metric.\n",
    "    - k_folds (int): The number of folds to use in K-Fold cross-validation.\n",
    "    - X (array-like): The feature dataset used for training the model.\n",
    "    - y (array-like): The target variable dataset used for training the model.\n",
    "\n",
    "    Returns:\n",
    "    - final_model (KNeighborsRegressor): The trained KNN regressor model using the best hyperparameters.\n",
    "\n",
    "    The function prints the MEE for each combination of hyperparameters during the grid search process.\n",
    "    After completing the search, it prints and returns the best hyperparameters along with their corresponding MEE.\n",
    "    \"\"\"\n",
    "    mees_mean = []\n",
    "    mees_sd = []\n",
    "    # Best k and its corresponding score\n",
    "    best_k = None\n",
    "    best_score = float('inf')\n",
    "\n",
    "    # K-Fold cross-validation\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Trying different combinations of hyperparams\n",
    "    for k, weights, p in product(ks, weightss,ps):\n",
    "        model = KNeighborsRegressor(n_neighbors=k, weights=weights, p=p)\n",
    "        # Negative Mean Squared Error as scoring\n",
    "        scores = cross_val_score(model, X, y, cv=kf, scoring=mean_euclidean_scorer)\n",
    "        mean_score = -scores.mean()  # Convert back to positive MSE\n",
    "        mees_mean.append(mean_score)\n",
    "        mees_sd.append(-scores.std())\n",
    "        print(f\"k={k}, w={weights}, p={p}, Mean Squared Error: {mean_score}\")\n",
    "\n",
    "        if mean_score < best_score:\n",
    "            best_k = k\n",
    "            best_weight = weights\n",
    "            best_p = p\n",
    "            best_score = mean_score\n",
    "\n",
    "    print(f\"The best k is {best_k} {best_weight} {best_p}  with a MEE of {best_score}\")\n",
    "\n",
    "    #  train the final model with the best k\n",
    "    final_model = KNeighborsRegressor(n_neighbors=best_k, weights=best_weight,p = best_p)\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid search\n",
    "ks = range(1, 31)\n",
    "weightss=['uniform','distance']\n",
    "ps = range(1,10)\n",
    "perform_grid_search_kfold(ks,weightss,ps,k_folds=3,X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study the effect of K\n",
    "keeping fixed the others hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mees_mean = []\n",
    "mees_sd = []\n",
    "# Best k and its corresponding score\n",
    "best_k = None\n",
    "best_score = float('inf')\n",
    "\n",
    "k_values = range(1, 31)\n",
    "\n",
    "# K-Fold cross-validation\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Trying different k values\n",
    "for k in k_values:\n",
    "    model = KNeighborsRegressor(n_neighbors=k, weights='distance',p = 1)\n",
    "    # Negative Mean Squared Error as scoring\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=kf, scoring=mean_euclidean_scorer)\n",
    "    mean_score = -scores.mean()  # Convert back to positive MSE\n",
    "    mees_mean.append(mean_score)\n",
    "    mees_sd.append(scores.std())\n",
    "    print(f\"k={k} Mean Squared Error: {mean_score}\")\n",
    "\n",
    "    if mean_score < best_score:\n",
    "        best_k = k\n",
    "        best_score = mean_score\n",
    "        best_score_sd = scores.std()\n",
    "\n",
    "print(f\"The best k is {best_k}  with a MEE of {best_score:.4} +- {best_score_sd:.4}\")\n",
    "\n",
    "#  train the final model with the best k\n",
    "final_model = KNeighborsRegressor(n_neighbors=best_k, weights='distance',p = 1)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "plot_mean_std(k_values,np.array(mees_mean),np.array(mees_sd),label='k', color='purple')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
