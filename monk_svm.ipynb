{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_euclidean_error(vectors1, vectors2):\n",
    "    \"\"\"\n",
    "    Compute the mean Euclidean error between two sets of 3D vectors.\n",
    "\n",
    "    Parameters:\n",
    "    - vectors1: NumPy array of shape (N, 3) representing the first set of 3D vectors\n",
    "    - vectors2: NumPy array of shape (N, 3) representing the second set of 3D vectors\n",
    "\n",
    "    Returns:\n",
    "    - mean_error: Mean Euclidean error between the two sets of vectors\n",
    "    \"\"\"\n",
    "    # Check if the input arrays have the correct shape\n",
    "    if vectors1.shape != vectors2.shape or vectors1.shape[1] != 3:\n",
    "        raise ValueError(\"Input arrays must be of shape (N, 3)\")\n",
    "\n",
    "    # Compute Euclidean distance\n",
    "    euclidean_distance = np.linalg.norm(vectors1 - vectors2, axis=1)\n",
    "\n",
    "    # Calculate the mean Euclidean error\n",
    "    mean_error = np.mean(euclidean_distance)\n",
    "\n",
    "    return mean_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_monk(file_name):\n",
    "    '''\n",
    "    Load data from the Monk dataset and preprocess using one-hot encoding.\n",
    "\n",
    "    Parameters:\n",
    "    - file_name (str): The file name of the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - x (torch.Tensor): Input data after one-hot encoding.\n",
    "    - y (torch.Tensor): Target data.\n",
    "    '''\n",
    "\n",
    "    # load the dataset, split into input (X) and output (y) variables\n",
    "    df = pd.read_csv(file_name, delimiter=' ', header=None,\n",
    "                     names=['_','target', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'data_number'],\n",
    "                     index_col=False)\n",
    "\n",
    "    # Extract input features and target variable\n",
    "    x1, x2, x3, x4, x5, x6, target = (np.array(df[feature]) for feature in ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'target'])\n",
    "\n",
    "    # Initialize OneHotEncoder\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "    # Reshape and transform x1 using one-hot encoding\n",
    "    input_one_hot = encoder.fit_transform(x1.reshape(-1, 1))\n",
    "\n",
    "    # Loop through the remaining input features and concatenate one-hot encoded values\n",
    "    for x in [x2,x3,x4,x5,x6]:\n",
    "        data =x.reshape(-1, 1)\n",
    "        one_hot_encoded = encoder.fit_transform(data)\n",
    "        input_one_hot = np.hstack((input_one_hot, one_hot_encoded))\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    x = torch.tensor(input_one_hot, dtype=torch.float32)#.cuda()\n",
    "    y = torch.tensor(target, dtype=torch.float32).reshape(-1,1)#.cuda()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# load the dataset, split into input (X) and output (y) variables\n",
    "dataset = np.loadtxt('ML-CUP23-TR.csv', delimiter=',')\n",
    "X = dataset[:,1:11]\n",
    "y = dataset[:,11:14]\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets (80%/20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search_kfold(kernels, Cs, k_folds, x, y):\n",
    "    '''\n",
    "    Perform grid search with k-fold cross-validation for Monk classifier hyperparameters.\n",
    "\n",
    "    Parameters:\n",
    "    - hidden_sizes (list): List of hidden layer sizes to explore.\n",
    "    - learning_rates (list): List of learning rates to explore.\n",
    "    - momentums (list): List of momentum values to explore.\n",
    "    - batch_sizes (list): List of batch sizes to explore.\n",
    "    - reg_coeffs (list): List of regularization coefficients to explore.\n",
    "    - k_folds (int): Number of folds for cross-validation.\n",
    "    - x (torch.Tensor): Input data.\n",
    "    - y (torch.Tensor): Target data.\n",
    "    - plot_curves (bool): Whether to plot training curves for each hyperparameter combination (default: False).\n",
    "\n",
    "    Returns:\n",
    "    - best_hyperparams (list): List of best hyperparameters based on highest average validation accuracy.\n",
    "    '''\n",
    "\n",
    "    best_acc = 0\n",
    "    best_hyperparams = []\n",
    "\n",
    "    for kernel, C in product(kernels, Cs):\n",
    "        print('kernel:', kernel, 'C:',C)\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "        # Lists to store training and validation losses and accuracies for each epoch\n",
    "        val_acc = []\n",
    "        svm_classifier_rbf = SVC(kernel=kernel, C=C)\n",
    "        # Perform K-fold cross-validation\n",
    "        for fold, (train_indices, val_indices) in enumerate(kf.split(x,y)):\n",
    "            #print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "\n",
    "            # Split the data into training and validation (or test) sets\n",
    "            X_train, X_val = x[train_indices], x[val_indices]\n",
    "            Y_train, Y_val = y[train_indices], y[val_indices]\n",
    "\n",
    "            svm_classifier_rbf.fit(X_train, Y_train)\n",
    "            y_pred_rbf = svm_classifier_rbf.predict(X_val)\n",
    "            accuracy_rbf = accuracy_score(Y_val, y_pred_rbf)\n",
    "\n",
    "            val_acc.append(accuracy_rbf)\n",
    "\n",
    "        print(f'{kernel}, C={C}, acc={np.mean(val_acc)}+-{np.std(val_acc)}')\n",
    "\n",
    "\n",
    "        if np.mean(val_acc) >= best_acc:\n",
    "            best_acc = np.mean(val_acc)\n",
    "            best_hyperparams = [kernel,C]\n",
    "\n",
    "    print(best_hyperparams)\n",
    "    return best_hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MONK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = preprocess_monk(file_name='monk_data/monks-1.train')\n",
    "x_test, y_test = preprocess_monk(file_name='monk_data/monks-1.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.1, 1, 100, 1000, 10000, 100000]\n",
      "kernel: rbf C: 0.01\n",
      "rbf, C=0.01, acc=0.5553619821912504+-0.09554017291293267\n",
      "kernel: rbf C: 0.1\n",
      "rbf, C=0.1, acc=0.5553619821912504+-0.09554017291293267\n",
      "kernel: rbf C: 1\n",
      "rbf, C=1, acc=0.8070073557878435+-0.04973517181408441\n",
      "kernel: rbf C: 100\n",
      "rbf, C=100, acc=0.8877274487030585+-0.06814882183447475\n",
      "kernel: rbf C: 1000\n",
      "rbf, C=1000, acc=0.8877274487030585+-0.06814882183447475\n",
      "kernel: rbf C: 10000\n",
      "rbf, C=10000, acc=0.8877274487030585+-0.06814882183447475\n",
      "kernel: rbf C: 100000\n",
      "rbf, C=100000, acc=0.8877274487030585+-0.06814882183447475\n",
      "['rbf', 100000]\n"
     ]
    }
   ],
   "source": [
    "kernels = ['rbf']\n",
    "Cs = [0.01,0.1,1,100,1000,10000,100000]\n",
    "print(Cs)\n",
    "best_hyperparams = perform_grid_search_kfold(kernels,\n",
    "                          Cs,\n",
    "                          k_folds=3,\n",
    "                          x=x_train,\n",
    "                          y=y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with RBF kernel: 0.9953703703703703\n"
     ]
    }
   ],
   "source": [
    "svm_classifier_rbf = SVC(kernel = best_hyperparams[0], C = best_hyperparams[1])\n",
    "svm_classifier_rbf.fit(x_train,y_train.ravel())\n",
    "# Make predictions on the test set\n",
    "y_pred_rbf = svm_classifier_rbf.predict(x_test)\n",
    "# Calculate accuracy\n",
    "accuracy_rbf = accuracy_score(y_test, y_pred_rbf)\n",
    "print(\"Accuracy with RBF kernel:\", accuracy_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MONK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = preprocess_monk(file_name='monk_data/monks-2.train')\n",
    "x_test, y_test = preprocess_monk(file_name='monk_data/monks-2.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.1, 1, 100, 1000, 10000, 100000]\n",
      "kernel: sigmoid C: 0.01\n",
      "sigmoid, C=0.01, acc=0.6213450292397661+-0.005168909219199899\n",
      "kernel: sigmoid C: 0.1\n",
      "sigmoid, C=0.1, acc=0.6213450292397661+-0.005168909219199899\n",
      "kernel: sigmoid C: 1\n",
      "sigmoid, C=1, acc=0.4737886382623225+-0.0542949917799745\n",
      "kernel: sigmoid C: 100\n",
      "sigmoid, C=100, acc=0.3670634920634921+-0.02494008946423916\n",
      "kernel: sigmoid C: 1000\n",
      "sigmoid, C=1000, acc=0.39066416040100255+-0.017335633248442263\n",
      "kernel: sigmoid C: 10000\n",
      "sigmoid, C=10000, acc=0.37896825396825395+-0.033082007937565605\n",
      "kernel: sigmoid C: 100000\n",
      "sigmoid, C=100000, acc=0.39066416040100255+-0.017335633248442263\n",
      "kernel: poly C: 0.01\n",
      "poly, C=0.01, acc=0.6213450292397661+-0.005168909219199899\n",
      "kernel: poly C: 0.1\n",
      "poly, C=0.1, acc=0.6213450292397661+-0.005168909219199899\n",
      "kernel: poly C: 1\n",
      "poly, C=1, acc=0.6747076023391813+-0.05414293621971112\n",
      "kernel: poly C: 100\n",
      "poly, C=100, acc=0.698203842940685+-0.043812880343637436\n",
      "kernel: poly C: 1000\n",
      "poly, C=1000, acc=0.698203842940685+-0.043812880343637436\n",
      "kernel: poly C: 10000\n",
      "poly, C=10000, acc=0.698203842940685+-0.043812880343637436\n",
      "kernel: poly C: 100000\n",
      "poly, C=100000, acc=0.698203842940685+-0.043812880343637436\n",
      "kernel: rbf C: 0.01\n",
      "rbf, C=0.01, acc=0.6213450292397661+-0.005168909219199899\n",
      "kernel: rbf C: 0.1\n",
      "rbf, C=0.1, acc=0.6213450292397661+-0.005168909219199899\n",
      "kernel: rbf C: 1\n",
      "rbf, C=1, acc=0.6096491228070176+-0.026151173878081725\n",
      "kernel: rbf C: 100\n",
      "rbf, C=100, acc=0.6447368421052632+-0.027912109783679515\n",
      "kernel: rbf C: 1000\n",
      "rbf, C=1000, acc=0.6447368421052632+-0.027912109783679515\n",
      "kernel: rbf C: 10000\n",
      "rbf, C=10000, acc=0.6447368421052632+-0.027912109783679515\n",
      "kernel: rbf C: 100000\n",
      "rbf, C=100000, acc=0.6447368421052632+-0.027912109783679515\n",
      "kernel: linear C: 0.01\n",
      "linear, C=0.01, acc=0.6213450292397661+-0.005168909219199899\n",
      "kernel: linear C: 0.1\n",
      "linear, C=0.1, acc=0.6213450292397661+-0.005168909219199899\n",
      "kernel: linear C: 1\n",
      "linear, C=1, acc=0.5265246449456975+-0.08833635949822699\n",
      "kernel: linear C: 100\n",
      "linear, C=100, acc=0.5148287385129491+-0.08758654971074988\n",
      "kernel: linear C: 1000\n",
      "linear, C=1000, acc=0.5148287385129491+-0.08758654971074988\n",
      "kernel: linear C: 10000\n",
      "linear, C=10000, acc=0.5148287385129491+-0.08758654971074988\n",
      "kernel: linear C: 100000\n",
      "linear, C=100000, acc=0.5148287385129491+-0.08758654971074988\n",
      "['poly', 100000]\n"
     ]
    }
   ],
   "source": [
    "kernels = ['sigmoid', 'poly', 'rbf', 'linear']\n",
    "Cs = [0.01,0.1,1,100,1000,10000,100000]\n",
    "print(Cs)\n",
    "best_hyperparams = perform_grid_search_kfold(kernels,\n",
    "                          Cs,\n",
    "                          k_folds=3,\n",
    "                          x=x_train,\n",
    "                          y=y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "Accuracy with RBF kernel: 0.7731481481481481\n"
     ]
    }
   ],
   "source": [
    "svm_classifier_rbf = SVC(kernel = best_hyperparams[0], C = best_hyperparams[1])\n",
    "svm_classifier_rbf.fit(x_train,y_train.ravel())\n",
    "# Make predictions on the test set\n",
    "y_pred_rbf = svm_classifier_rbf.predict(x_test)\n",
    "print(y_pred_rbf)\n",
    "# Calculate accuracy\n",
    "accuracy_rbf = accuracy_score(y_test, y_pred_rbf)\n",
    "print(\"Accuracy with RBF kernel:\", accuracy_rbf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
