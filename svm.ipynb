{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_euclidean_error(vectors1, vectors2):\n",
    "    \"\"\"\n",
    "    Compute the mean Euclidean error between two sets of 3D vectors.\n",
    "\n",
    "    Parameters:\n",
    "    - vectors1: NumPy array of shape (N, 3) representing the first set of 3D vectors\n",
    "    - vectors2: NumPy array of shape (N, 3) representing the second set of 3D vectors\n",
    "\n",
    "    Returns:\n",
    "    - mean_error: Mean Euclidean error between the two sets of vectors\n",
    "    \"\"\"\n",
    "    # Check if the input arrays have the correct shape\n",
    "    if vectors1.shape != vectors2.shape or vectors1.shape[1] != 3:\n",
    "        raise ValueError(\"Input arrays must be of shape (N, 3)\")\n",
    "\n",
    "    # Compute Euclidean distance\n",
    "    euclidean_distance = np.linalg.norm(vectors1 - vectors2, axis=1)\n",
    "\n",
    "    # Calculate the mean Euclidean error\n",
    "    mean_error = np.mean(euclidean_distance)\n",
    "\n",
    "    return mean_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# load the dataset, split into input (X) and output (y) variables\n",
    "dataset = np.loadtxt('ML-CUP23-TR.csv', delimiter=',')\n",
    "X = dataset[:,1:11]\n",
    "y = dataset[:,11:14]\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets (80%/20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiSVM:\n",
    "    def __init__(self, kernel='rbf', C=1.0, epsilon=0.1):\n",
    "        # Create three support vector regressors with the specified kernel, regularization parameter, and epsilon\n",
    "        self.svr0 = SVR(kernel=kernel, C=C, epsilon=epsilon)\n",
    "        self.svr1 = SVR(kernel=kernel, C=C, epsilon=epsilon)\n",
    "        self.svr2 = SVR(kernel=kernel, C=C, epsilon=epsilon)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Fit each SVR on its respective data\n",
    "        self.svr0.fit(X, y[:,0])\n",
    "        self.svr1.fit(X, y[:,1])\n",
    "        self.svr2.fit(X, y[:,2])\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions using each SVR\n",
    "        pred = np.column_stack((self.svr0.predict(X),self.svr1.predict(X),self.svr2.predict(X)))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search_kfold(kernels, Cs, epsilons, k_folds, x, y, return_sequence=False):\n",
    "    \"\"\"\n",
    "    Perform grid search with k-fold cross-validation for hyperparameters.\n",
    "\n",
    "    Parameters:\n",
    "    - neuron_numbers (list): List of neuron numbers to search.\n",
    "    - learning_rates (list): List of learning rates to search.\n",
    "    - momentums (list): List of momentum values to search.\n",
    "    - batch_sizes (list): List of batch sizes to search.\n",
    "    - reg_coeffs (list): List of regularization coefficients to search.\n",
    "    - activations (list): List of activation functions to search.\n",
    "    - layerss (list): List of numbers of hidden layers to search.\n",
    "    - k_folds (int): Number of folds for cross-validation.\n",
    "    - x (numpy.ndarray): Input data.\n",
    "    - y (numpy.ndarray): Target data.\n",
    "    - plot_curves (bool, optional): Whether to plot training curves (default: False).\n",
    "    - num_epochs (int, optional): Number of training epochs (default: 1000).\n",
    "\n",
    "    Returns:\n",
    "    - list: List of best hyperparameters.\n",
    "\n",
    "    The function performs grid search with k-fold cross-validation for Monk classifier hyperparameters and returns the best hyperparameters.\n",
    "    \"\"\"\n",
    "    mee_sequence = []\n",
    "    mee_sd_sequence = []\n",
    "    best_mee = float('inf')\n",
    "    best_mee_std = 0\n",
    "    best_hyperparams = []\n",
    "    counter = 0\n",
    "    num_combinations = sum(1 for _ in product(kernels, Cs,epsilons))\n",
    "    print('total number of grid search combinations explored:',num_combinations)\n",
    "    for kernel, C,epsilon in product(kernels, Cs,epsilons):\n",
    "        counter += 1\n",
    "        print(f'{counter}/{num_combinations} Hyperparams:',kernel, C, epsilon)\n",
    "\n",
    "        kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "        val_mees = []\n",
    "\n",
    "        # Perform K-fold cross-validation\n",
    "        for fold, (train_indices, val_indices) in enumerate(kf.split(x,y)):\n",
    "            #print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "\n",
    "            # Split the data into training and validation (or test) sets\n",
    "            X_train, X_val = x[train_indices], x[val_indices]\n",
    "            y_train, y_val = y[train_indices], y[val_indices]\n",
    "\n",
    "            model = MultiSVM(kernel, C, epsilon)\n",
    "            model.fit(X_train,y_train)\n",
    "            val_mees.append(mean_euclidean_error(model.predict(X_val),y_val))\n",
    "\n",
    "        print(f'Final Results: kernel={kernel}; C={C}; epsilon={epsilon} --> '\n",
    "            f'val_mee = {np.mean(val_mees):.4} +- {np.std(val_mees):.4}')\n",
    "\n",
    "        mee_sequence.append(np.mean(val_mees))\n",
    "        mee_sd_sequence.append(np.std(val_mees))\n",
    "        if np.mean(val_mees) < best_mee:\n",
    "            best_mee = np.mean(val_mees)\n",
    "            best_mee_std = np.std(val_mees)\n",
    "            best_hyperparams = [kernel, C, epsilon]\n",
    "\n",
    "    print(f'Best Hp: {best_hyperparams} with MEE = {best_mee} +- {best_mee_std}')\n",
    "    if return_sequence:\n",
    "        return best_hyperparams, mee_sequence, mee_sd_sequence\n",
    "    else:\n",
    "        return best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of grid search combinations explored: 25\n",
      "1/25 Hyperparams: rbf 1000 0.1\n",
      "Final Results: kernel=rbf; C=1000; epsilon=0.1 --> val_mee = 0.6397 +- 0.0498\n",
      "2/25 Hyperparams: rbf 1000 0.2\n",
      "Final Results: kernel=rbf; C=1000; epsilon=0.2 --> val_mee = 0.6635 +- 0.04859\n",
      "3/25 Hyperparams: rbf 1000 0.3\n",
      "Final Results: kernel=rbf; C=1000; epsilon=0.3 --> val_mee = 0.7216 +- 0.05159\n",
      "4/25 Hyperparams: rbf 1000 0.4\n",
      "Final Results: kernel=rbf; C=1000; epsilon=0.4 --> val_mee = 0.7893 +- 0.04696\n",
      "5/25 Hyperparams: rbf 1000 0.5\n",
      "Final Results: kernel=rbf; C=1000; epsilon=0.5 --> val_mee = 0.8715 +- 0.04746\n",
      "6/25 Hyperparams: rbf 2000 0.1\n",
      "Final Results: kernel=rbf; C=2000; epsilon=0.1 --> val_mee = 0.6185 +- 0.0589\n",
      "7/25 Hyperparams: rbf 2000 0.2\n",
      "Final Results: kernel=rbf; C=2000; epsilon=0.2 --> val_mee = 0.65 +- 0.05142\n",
      "8/25 Hyperparams: rbf 2000 0.3\n",
      "Final Results: kernel=rbf; C=2000; epsilon=0.3 --> val_mee = 0.7114 +- 0.05378\n",
      "9/25 Hyperparams: rbf 2000 0.4\n",
      "Final Results: kernel=rbf; C=2000; epsilon=0.4 --> val_mee = 0.7749 +- 0.04972\n",
      "10/25 Hyperparams: rbf 2000 0.5\n",
      "Final Results: kernel=rbf; C=2000; epsilon=0.5 --> val_mee = 0.8589 +- 0.05031\n",
      "11/25 Hyperparams: rbf 3000 0.1\n",
      "Final Results: kernel=rbf; C=3000; epsilon=0.1 --> val_mee = 0.6173 +- 0.06577\n",
      "12/25 Hyperparams: rbf 3000 0.2\n",
      "Final Results: kernel=rbf; C=3000; epsilon=0.2 --> val_mee = 0.6487 +- 0.05605\n",
      "13/25 Hyperparams: rbf 3000 0.3\n",
      "Final Results: kernel=rbf; C=3000; epsilon=0.3 --> val_mee = 0.7064 +- 0.05627\n",
      "14/25 Hyperparams: rbf 3000 0.4\n",
      "Final Results: kernel=rbf; C=3000; epsilon=0.4 --> val_mee = 0.7723 +- 0.05118\n",
      "15/25 Hyperparams: rbf 3000 0.5\n",
      "Final Results: kernel=rbf; C=3000; epsilon=0.5 --> val_mee = 0.8589 +- 0.05017\n",
      "16/25 Hyperparams: rbf 4000 0.1\n",
      "Final Results: kernel=rbf; C=4000; epsilon=0.1 --> val_mee = 0.6195 +- 0.07081\n",
      "17/25 Hyperparams: rbf 4000 0.2\n",
      "Final Results: kernel=rbf; C=4000; epsilon=0.2 --> val_mee = 0.6483 +- 0.06135\n",
      "18/25 Hyperparams: rbf 4000 0.3\n",
      "Final Results: kernel=rbf; C=4000; epsilon=0.3 --> val_mee = 0.7082 +- 0.05893\n",
      "19/25 Hyperparams: rbf 4000 0.4\n",
      "Final Results: kernel=rbf; C=4000; epsilon=0.4 --> val_mee = 0.7729 +- 0.05139\n",
      "20/25 Hyperparams: rbf 4000 0.5\n",
      "Final Results: kernel=rbf; C=4000; epsilon=0.5 --> val_mee = 0.8589 +- 0.05017\n",
      "21/25 Hyperparams: rbf 5000 0.1\n",
      "Final Results: kernel=rbf; C=5000; epsilon=0.1 --> val_mee = 0.6214 +- 0.07408\n",
      "22/25 Hyperparams: rbf 5000 0.2\n",
      "Final Results: kernel=rbf; C=5000; epsilon=0.2 --> val_mee = 0.6515 +- 0.06553\n",
      "23/25 Hyperparams: rbf 5000 0.3\n",
      "Final Results: kernel=rbf; C=5000; epsilon=0.3 --> val_mee = 0.7115 +- 0.05946\n",
      "24/25 Hyperparams: rbf 5000 0.4\n",
      "Final Results: kernel=rbf; C=5000; epsilon=0.4 --> val_mee = 0.7729 +- 0.0514\n",
      "25/25 Hyperparams: rbf 5000 0.5\n",
      "Final Results: kernel=rbf; C=5000; epsilon=0.5 --> val_mee = 0.8589 +- 0.05017\n",
      "Best Hp: ['rbf', 3000, 0.1] with MEE = 0.6172759223965806 +- 0.06576969897515686\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#first coarse grid search\n",
    "kernels = ['rbf']\n",
    "Cs = [0.01,0.1,1,10,100,1000]\n",
    "epsilons = [0.01,0.1,1,10]\n",
    "#Best Hp: ['rbf', 1000, 0.1] with MEE = 0.6396615599226871 +- 0.04980493197143183\n",
    "'''\n",
    "\n",
    "'''\n",
    "#finer grid search\n",
    "kernels = ['rbf']\n",
    "Cs = [1000,2000,3000,4000,5000]\n",
    "epsilons = [0.1,0.2,0.3,0.4,0.5]\n",
    "# Best Hp: ['rbf', 3000, 0.1] with MEE = 0.6172759223965806 +- 0.06576969897515686\n",
    "'''\n",
    "\n",
    "best_hyperparams = perform_grid_search_kfold(kernels,\n",
    "                          Cs,\n",
    "                          epsilons,\n",
    "                          k_folds=3,\n",
    "                          x=X_train,\n",
    "                          y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the effect of the parameter C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of grid search combinations explored: 4\n",
      "1/4 Hyperparams: rbf 10 0.1\n",
      "Final Results: kernel=rbf; C=10; epsilon=0.1 --> val_mee = 1.609 +- 0.08875\n",
      "2/4 Hyperparams: rbf 20 0.1\n",
      "Final Results: kernel=rbf; C=20; epsilon=0.1 --> val_mee = 1.375 +- 0.08206\n",
      "3/4 Hyperparams: rbf 30 0.1\n",
      "Final Results: kernel=rbf; C=30; epsilon=0.1 --> val_mee = 1.255 +- 0.0801\n",
      "4/4 Hyperparams: rbf 40 0.1\n",
      "Final Results: kernel=rbf; C=40; epsilon=0.1 --> val_mee = 1.172 +- 0.07708\n",
      "Best Hp: ['rbf', 40, 0.1] with MEE = 1.172096760255979 +- 0.07707830189581184\n"
     ]
    }
   ],
   "source": [
    "kernels = ['rbf']\n",
    "Cs = [10,20,30,40]\n",
    "epsilons = [0.1]\n",
    "\n",
    "\n",
    "best_hyperparams, mees, mees_sd = perform_grid_search_kfold(kernels,\n",
    "                          Cs,\n",
    "                          epsilons,\n",
    "                          k_folds=3,\n",
    "                          x=X_train,\n",
    "                          y=y_train,\n",
    "                          return_sequence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_std(cs,mee,std,label):\n",
    "\n",
    "    plt.figure(figsize=(9, 8))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(mean_tr, label=f'Training {label} (mean $\\pm$ std)', color = 'red', linewidth=1)\n",
    "    plt.fill_between(range(0,len(train_hist[0])),mean_tr-std_tr, mean_tr+std_tr, color='crimson', alpha=0.3)\n",
    "\n",
    "    plt.plot(mean_te, label=f'Test {label} (mean $\\pm$ std)', color = 'blue', linestyle='--', linewidth=1)\n",
    "    plt.fill_between(range(0,len(test_hist[0])),mean_te-std_te, mean_te+std_te, color='blue', alpha=0.3)\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(label)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(label)\n",
    "    plt.ylim(0,1)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5050968675207652\n"
     ]
    }
   ],
   "source": [
    "model = MultiSVM(*best_hyperparams)\n",
    "model.fit(X_train,y_train)\n",
    "print(mean_euclidean_error(model.predict(X_test),y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
